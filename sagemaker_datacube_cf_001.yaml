AWSTemplateFormatVersion: 2010-09-09
Description: IAM Policies, and SageMaker Notebook with Lifecycle configuration for the Semantic Segmentation on Satellite imagery workshop. The template will also clone the codebase into the Notebook before you get started.

Metadata:
  AWS::CloudFormation::Interface:
    ParameterLabels:
      NotebookName:
        default: Notebook Name

Parameters: 
  NotebookName:
    Type: String
    Default: DatacubeSageMakerNotebook
    Description: Enter the name of the SageMaker Notebook instance. Default is DatacubeSageMakerNotebook.

  SubnetId:
    Type: String
    Default: subnet-5209c034
    Description: Enter the name of the SageMaker Notebook instance. Default is DatacubeSageMakerNotebook.

  SecurityGroupId:
    Type: String
    Default: sg-f661dfbc
    Description: Enter the name of the SageMaker Notebook instance. Default is DatacubeSageMakerNotebook.
  

Resources: 
# SageMaker Execution Role
  SageMakerIamRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: Allow
            Principal:
              Service: sagemaker.amazonaws.com
            Action: sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess"
        - "arn:aws:iam::aws:policy/AmazonS3FullAccess"
        - "arn:aws:iam::aws:policy/IAMFullAccess"

  DatacubeInstanceLifecycleConfig:
    Type: "AWS::SageMaker::NotebookInstanceLifecycleConfig"
    Properties:
      OnStart:
        - Content:           
            Fn::Base64: |
              #!/bin/bash

              set -e

              # OVERVIEW
              # This script installs a custom, persistent installation of conda on the Notebook Instance's EBS volume, and ensures
              # that these custom environments are available as kernels in Jupyter.
              # 
              # The on-start script uses the custom conda environment created in the on-create script and uses the ipykernel package
              # to add that as a kernel in Jupyter.
              #
              # For another example, see:
              # https://docs.aws.amazon.com/sagemaker/latest/dg/nbi-add-external.html#nbi-isolated-environment

              sudo -u ec2-user -i <<'EOF'
              unset SUDO_UID

              KERNEL_NAME="odc_python36"
              WORKING_DIR=/home/ec2-user/SageMaker/custom-miniconda/
              source "$WORKING_DIR/miniconda/bin/activate"
              conda activate "$KERNEL_NAME"

              gdal_installed=$(conda list | grep -w "gdal")
              if [ -z "${gdal_installed}" ]; then
                conda install -y gdal==3.2.1
              fi

              # sagemaker_installed=$(conda list | grep sagemaker)
              # if [ -z "${sagemaker_installed}" ]; then
              #   yes | pip install \
              #           matplotlib==3.3.4 \
              #           scipy==1.5.3 \
              #           pydotplus==2.0.2 \
              #           joblib==1.0.1 \
              #           scikit-learn==0.24.1 \
              #           folium==0.12.0 \
              #           dask-ml==1.8.0 \
              #           geopandas==0.8.2 \
              #           ipywidgets==7.6.3 \
              #           ipyleaflet==0.13.6 \
              #           boto3==1.16.52 \
              #           botocore==1.19.52 \
              #           rasterstats==0.14.0 \
              #           sagemaker==2.26.0 \
              #           smdebug-rulesconfig==1.0.1
              # fi

              datacube_stats_installed=$(conda list | grep datacube-stats)
              if [ -z "${datacube_stats_installed}" ]; then
                yes | pip install git+https://github.com/opendatacube/datacube-stats/
              fi

              odc_ones_installed=$(conda list | grep odc-ui)
              if [ -z "${odc_ones_installed}" ]; then
                yes | pip install --extra-index-url="https://packages.dea.ga.gov.au" \
                        odc-ui \
                        odc-index \
                        odc-geom \
                        odc-algo \
                        odc-io \
                        odc-aws \
                        odc-aio \
                        odc-dscache \
                        odc-dtools
              fi
              
              hdstats_installed=$(conda list | grep hdstats)
              if [ -z "${odc_ones_installed}" ]; then
                cd /tmp
                wget https://packages.dea.ga.gov.au/hdstats/hdstats-0.1.8.post1-cp36-cp36m-manylinux2010_x86_64.whl
                yes | pip install hdstats-0.1.8.post1-cp36-cp36m-manylinux2010_x86_64.whl
              fi

              # enable kernel name in the list
              python -m ipykernel install --user --name "$KERNEL_NAME"  --display-name "$KERNEL_NAME"
              EOF

              # setup datacube.conf
              wget http://d1uvw90uyir5vw.cloudfront.net/datacube.conf
              cp datacube.conf /etc/datacube.conf

              echo "Restarting the Jupyter server.."
              restart jupyter-server
      OnCreate: 
        - Content: 
            Fn::Base64: |
              #!/bin/bash

              set -e

              # OVERVIEW
              # This script installs a custom, persistent installation of conda on the Notebook Instance's EBS volume, and ensures
              # that these custom environments are available as kernels in Jupyter.
              # 
              # The on-create script downloads and installs a custom conda installation to the EBS volume via Miniconda. Any relevant
              # packages can be installed here.
              #   1. ipykernel is installed to ensure that the custom environment can be used as a Jupyter kernel   
              #   2. Ensure the Notebook Instance has internet connectivity to download the Miniconda installer


              sudo -u ec2-user -i <<'EOF'
              unset SUDO_UID
              # Install a separate conda installation via Miniconda
              WORKING_DIR=/home/ec2-user/SageMaker/custom-miniconda
              mkdir -p "$WORKING_DIR"
              wget https://repo.anaconda.com/miniconda/Miniconda3-4.6.14-Linux-x86_64.sh -O "$WORKING_DIR/miniconda.sh"
              bash "$WORKING_DIR/miniconda.sh" -b -u -p "$WORKING_DIR/miniconda" 
              rm -rf "$WORKING_DIR/miniconda.sh"

              # Create a custom conda environment
              source "$WORKING_DIR/miniconda/bin/activate"
              KERNEL_NAME="odc_python36"
              PYTHON="3.6"
              conda create --yes --name "$KERNEL_NAME" python="$PYTHON" datacube==1.8.3

              # install ipykernel 
              conda activate "$KERNEL_NAME"
              
              yes | pip install ipykernel

              yes | pip install \
                      matplotlib==3.3.4 \
                      scipy==1.5.3 \
                      pydotplus==2.0.2 \
                      joblib==1.0.1 \
                      scikit-learn==0.24.1 \
                      folium==0.12.0 \
                      dask-ml==1.8.0 \
                      geopandas==0.8.2 \
                      ipywidgets==7.6.3 \
                      ipyleaflet==0.13.6 \
                      boto3==1.16.52 \
                      botocore==1.19.52 \
                      rasterstats==0.14.0 \
                      sagemaker==2.26.0 \
                      smdebug-rulesconfig==1.0.1

              EOF

  # SageMaker notebook
  NotebookInstance:
    Type: "AWS::SageMaker::NotebookInstance"
    Properties:
      DefaultCodeRepository: "https://github.com/digitalearthafrica/deafrica-sandbox-notebooks.git"
      InstanceType: "ml.t3.xlarge"
      NotebookInstanceName: !Ref NotebookName
      RoleArn: !GetAtt SageMakerIamRole.Arn
      LifecycleConfigName: !GetAtt DatacubeInstanceLifecycleConfig.NotebookInstanceLifecycleConfigName
      VolumeSizeInGB: 30 
      SubnetId: !Ref SubnetId
      SecurityGroupIds:
        - !Ref SecurityGroupId

Outputs:
  NotebookInstanceId:
    Value: !Ref NotebookInstance
  NotebookInstanceLifecycleConfigId:
    Value: !Ref DatacubeInstanceLifecycleConfig